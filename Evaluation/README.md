# Evaluation

###### Authors: Giulia Del Citto, Diego Sonaglia, Roberto Sorce

To properly evaluate our product, according to our case of study, we decided to resort to the User Centered Design (__UCD__), considering different perspectives and factors that can affect the user experience.

We are going to use a mixture of both subjective and objective metrics to evaluate the quality of service (__QoS__) and to understand how to improve it.

At the end of the museum tour, we'd like to collect the opinions of the users by prompting to submit a form with questions about: 

### Evaluation of the overall system:

  ##### Attractiveness 
 Overall impression of the product. We're concerned about the design and perception of the product from the user point of view. Does it catch the interest of users? Is it entertaining? 

  ##### Interaction
 From the interaction point of view, we ask ourselves if the users find easy to get familiar with our product and to learn how to use it. Does the user feel in control of the interaction? Is it predictable? 

  ##### Efficiency
 How the product behaves in terms of reaction? Does it respond fast enough? Does the system behave correctly? 

  ##### Motivation
 The solution we are proposing is motivating to justify the use of the product during the tour? Is it fun to use? Does the user perceive it as a useful tool to enrich the tour experience offered by the museum? Did it change your experience?


### Evaluation of individual components

For what concerns the evaluation of each component of our system, we report below the metrics considered, always taking into account the __UCD__.

- Regarding the website:
  - Does it look good?
  - Is it easy to use? 
  - Did it work, or did it break?
  - and so on and so forth.
  - Gather impressions from the users about the usage, or suggestions to improve the experience.

- Regarding the Cube:
  - Does it look familiar?
  - Does it feel handy (too big or too small)?
  - Is it easy to use? 
  - Did it work, or did it break?
  - Gather impressions from the users about the usage, or suggestions to improve the experience.
  
### Evaluation of technical aspects

Technical aspect of the product evaluation includes:

- Metrics about the game statistics
- Number of matches (in one day)
- Average number of players per match
- Statistics about correct/wrong answers
- Relative elapsed time per each question
- Total elapsed time
- Total tour time
- Failure/Anomalies detection 
- Number of visitors that decided to use the __Magic cube__ 
- Behaviors wrt numbers of cubes running and exchanging messages with the broker





