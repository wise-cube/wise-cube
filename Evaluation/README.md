# Evaluation

###### Authors: Giulia Del Citto, Diego Sonaglia, Roberto Sorce

To properly evaluate our product, according to our case of study, we decided to resort to the User Centered Design (__UCD__), considering different perspectives and factors that can affect the user experience.

We are going to use a mixture of both subjective and objective metrics to evaluate the quality of service (__QoS__) and to understand how to improve it.

- [X] Brainstorming 
- [X] Mockup
- [X] Evaluation 1
- [ ] **Prototyping**
- [ ] Evaluation 2
- [ ] Product Development
- [ ] Evaluation 3 ( feedback )

After showing our product using a mockup, we'd like to collect the opinions of the users by prompting to submit a form with questions about: 

### Evaluation goals

  ##### Attractiveness 
 Overall impression of the product. We're concerned about the design and perception of the product from the user point of view. Does it catch the interest of users? Is it entertaining? 

  ##### Ease of interaction
 From the interaction point of view, we ask ourselves if the users find easy to get familiar with our product and to learn how to use it. Does the user feel in control of the interaction? Is it predictable? 

  ##### Motivation
 The solution we are proposing is motivating to justify the use of the product during the tour? Is it fun to use? Does the user perceive it as a useful tool to enrich the tour experience offered by the museum? Did it change your experience?


### Evaluation of the user experience

For what concerns the evaluation of each component of our system, we report below the metrics considered, always taking into account the __UCD__.

- __Subjective evaluation__: Our users have been subjected to fill a questionnaire, in order to gather suggestions to improve the experience. The data collected through a [Google form](https://forms.gle/j8imT1uCAk1TxU6y6), about the product and its usage, are useful to measure:
  - The user's learning rate with the help of our product
  - Impact on the museum tour using Wise-cube
  - Ease of use of the IoT system
  - Innovative interactive experience from the user's point of view
  - Familiar design
  - Difficulties on the usage of a dedicated app (i.e. A QR code scanner)

- __Objective evaluation__: Statistic analysis of data coming from different contexts (i.e. questionnaire); Due to COVID-19 emergency, some effective measurments are not possible to carry out on the field, at the moment. 
  - Statistic effective learning rate based on the game results 
  - Number of participants 
  - Number of game played 
  - Potentially growth of visitors of the museum, wrt the avarage of visitors without the proposed IoT system
  
  #### Submit to the users the prototype, to retrieve important feedbacks about the game and the tour guide

- __Game Web app evaluation__: 
  - User interaction (attractive interface)
  - Severity of questions, regarding the level of difficulty (e.g. Kid's tour, standard tour)
  
- __Guide Web app evaluation__:
  - User interaction (attractive interface)
  - comprehensiveness of the exposition and the contents, regarding the level of difficulty (e.g. Kid's tour, standard tour)
  
### Evaluation of technical aspects

Technical aspect of the product evaluation includes:

- Failures/Anomalies detection during the communication among each part
- Behaviours wrt numbers of cubes running and exchanging messages with the broker in terms of latency
- The ratio between number of players (phones) connected and efficiency
- How the responsiveness of the webserver change  during the "stress test"







